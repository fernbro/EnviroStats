---
title: 'HW2: Continuous, fixed spatial index'
author: "Fern Bromley"
date: "**October 3, 2025**"
output:
  pdf_document
header-includes:
- \renewcommand*\familydefault{\sfdefault} %% this picks a sans serif font
- \usepackage[T1]{fontenc}
---

## I. Mathematical [6 pts]

(@) [6 pts] From Section 6.6 in ZVH, do **either** exercise 5. or 9. For 9., three covariance functions from each table (6.1 and 6.2) is sufficient.

Answering Exercise #9:

```{r}
# set up distances; use alpha = 4 as default since that should just be the range.... right?!
dists <- seq(0, 4, by = 0.1)
alpha <- 4
```

```{r}
fun1 <- 1 - (15*dists/(8*alpha)) + (5*(dists^3)/(4*(alpha^3))) - (3*(dists^5)/(8*(alpha^5)))
plot(dists, fun1, main = "Pentaspherical", ylab = "rho", xlab = "distance")
```

```{r}
fun2 <- 1 - (7*(dists^2)/(alpha^2)) + (35*(dists^3)/(4*(alpha^3))) - (7*(dists^5)/(2*(alpha^5))) + (3*(dists^7)/(4*(alpha^7)))
plot(dists, fun2, main = "Cubic", ylab = "rho", xlab = "distance")
```
```{r}
fun3 <- (2/pi)*(acos(dists/alpha) - ((dists/alpha)*sqrt(1-((dists/alpha)^2))) - ((2*dists/(3*alpha))*((1-((dists/alpha)^2))^(3/2))))
plot(dists, fun3, main = "Tetraspherical")
```
```{r}
# generalized cauchy

theta <- 1
phi = 3

fun4 <- (1+((dists/alpha)^theta))^(-phi)
plot(dists, fun4, main = "Generalized Cauchy (theta = 1, phi = 3)", 
     xlab = "distance", ylab = "rho")
```
```{r}
# gen cauchy 
theta_a <- 0.5
phi_a <-  3
alpha4 <- 2

fun4_a <- (1+((dists/alpha)^theta_a))^(-phi_a)

plot(dists, fun4_a, main = "Generalized Cauchy (theta = 0.5, phi = 3)", 
     xlab = "distance", ylab = "rho")

theta_b <- 2
phi_b = 4

fun4_b <- (1+((dists/alpha)^theta_b))^(-phi_b)

plot(dists, fun4_b, main = "Generalized Cauchy (theta = 2, phi = 4)", 
     xlab = "distance", ylab = "rho")
```

```{r}
# gravity because i like the name :)

alpha_5 <- 0.1
fun5 <- (1+((dists/alpha_5)^2))^(-1/2)

alpha_5a <- 0.3
fun5a <- (1+((dists/alpha_5a)^2))^(-1/2)

plot(dists, fun5, main = "Gravity (alpha = 0.1)",
          xlab = "distance", ylab = "rho")
plot(dists, fun5a, main = "Gravity (alpha = 0.3)",
     xlab = "distance", ylab = "rho")
```
```{r}
# radon transform of exponential, order 4
alpha_6 <- 0.5
alpha_6a <- 0.1

fun6 <- (1+(dists/alpha_6) + ((1/3)*((dists/alpha_6)^2)))*exp(-dists/alpha_6)
fun6a <- (1+(dists/alpha_6a) + ((1/3)*((dists/alpha_6a)^2)))*exp(-dists/alpha_6a)

plot(dists, fun6, main = "Radon transform (alpha = 0.5)",
     xlab = "distance", ylab = "rho")
plot(dists, fun6a, main = "Radon transform (alpha = 0.1)",
     xlab = "distance", ylab = "rho")
```

## II. Tucson Water [28 pts]

The Arizona Department Of Environmental Quality (ADEQ) monitors ground water for a large number of potentially hazardous chemicals at sites around the state. One such chemical is [**1,4-Dioxane**](https://en.wikipedia.org/wiki/1%2C4-Dioxane), which has a number of industrial uses, but is also irritating to eyes and respiratory systems, and is a possible carcinogen. The data in `1_4_dioxane.csv` were gathered from [**https://www.waterqualitydata.us/**](https://www.waterqualitydata.us/) and represent concentrations of the chemical 1,4-Dioxane in ground water near Tucson as measured in micrograms per liter (`ResultMeasureValue`). Each measurement is associated with a date (`AnalysisStartDate`) and the coordinates of the monitoring site (`Longitude`/`LatitudeMeasure`). In addition, a binary variable indicating whether or not the monitoring site is located within the boundary of Tucson International Airport (TIA) is also included (`airport`). 

(@) [2 pts] Create a map like the one shown (see Gradescope PDF) to visualize the spatial arrangement of log-dioxane concentrations. Be sure to choose colors appropriate for the measured variable. **Provide executable code (PEC)**.

```{r}
library(sf)
diox <- read.csv("1_4_dioxane.csv")
diox$log_diox <- log(diox$ResultMeasureValue)
bbox <- c(left = -111, bottom = 32.08, right = -110.93, top = 32.18)
diox_map <- ggmap::get_stadiamap(bbox = bbox, zoom = 15)

library(ggmap)

library(viridisLite)

ggmap(diox_map)+
  geom_point(data = diox, 
             aes(x = LongitudeMeasure, y = LatitudeMeasure,
                 color = log_diox))+
  scale_color_gradientn(colors = viridis(256, option = "B", direction = -1))
```


(@) [3 pts] Make a scatterplot showing log-dioxane as a function of the date each measurement was taken. Does your plot suggest time is related to concentrations of dioxane? Make a figure with two boxplots of log-dioxane grouped by whether or not sites are located at the airport or not. Does your figure suggest that sites at the airport have meaningfully different concentrations than other sites?

```{r}
ggplot(diox, aes(x = as.POSIXct(AnalysisStartDate), y = log_diox))+
  geom_point()
```
It would not appear from the scatterplot that the log dioxane concentration is following an interannual temporal pattern, but there might be some seasonality.

```{r}
ggplot(diox)+
  geom_boxplot(aes(x = airport, y = log_diox))
```
The box plot does suggest that the airport could have a higher mean log dioxane concentration.

(@) [3 pts] Transform the dioxane data to a new projection (coordinate reference system) corresponding to UTM zone 12N. **(PEC)**. Make an empirical semivariogram for the log-concentration of dioxane after accounting for possible linear effects of date and whether a site is at the airport or not. Give a rough estimate for the size of the nugget effect.

```{r}
diox_sf <- st_as_sf(diox, coords = c("LongitudeMeasure", "LatitudeMeasure"),
                    crs = "epsg:4269")
diox_12n <- st_transform(diox_sf, crs = "epsg:32612")
```

```{r}
# ok now we account for linear effect of date and the airport location:
library(spmodel)
plot(esv(log_diox ~ as.POSIXct(AnalysisStartDate) + airport, diox_12n))
```
The nugget effect estimated from the empirical semivariogram appears to be around 0.4 - 0.5.


(@) [3 pts] Fit a spatial linear regression model using restricted maximum likelihood (REML) to log-concentrations of dioxane as a linear function of measurement date and whether a site is located at TIA. Use the MatÃ©rn parametric family of covariance functions. Report the estimated nugget, partial sill, and range parameters. Given your semivariogram from the previous problem, do the parameter estimates make sense to you?

```{r}
reml_mod <- splm(log_diox ~ as.POSIXct(AnalysisStartDate) + airport, 
                 data = diox_12n, estmethod = "reml",
                 spcov_type = "matern")
reml_mod$coefficients
```


(@) [3 pts] Fit the same spatial linear regression model to the observations using the two-stage semivariogram + weighted least squares (SV-WLS) approach. Report the estimated covariance function parameters. Which estimation method, REML or SV-WLS, do you think yields the most reasonable covariance function parameters?

```{r}
sv_wls_mod <- splm(log_diox ~ as.POSIXct(AnalysisStartDate) + airport, 
                 data = diox_12n, estmethod = "sv-wls",
                 spcov_type = "matern")
sv_wls_mod$coefficients
```
SV-WLS yielded more reasonable covariance function parameters.

(@) [3 pts] Use leave-one-out cross validation to compare the predictive performance of each fitted model (REML and SV-WLS). Which model is associated with the smallest mean squared prediction error?

```{r}
rbind(c("reml", spmodel::loocv(reml_mod)), 
      c("sv-wls", spmodel::loocv(sv_wls_mod)))
```

The first model using REML estimation had a lower MSPE.

(@) [2 pts] Create diagnostic plots to visually assess how reasonable the assumption of marginal normality is for each fitted model. Interpret your plots.

```{r}
plot(reml_mod, 1)
plot(esv(.std.resid ~ 1, augment(reml_mod)))

plot(sv_wls_mod, 1)
plot(esv(.std.resid ~ 1, augment(sv_wls_mod)))

```
For both models, the residuals appear normally distributed, and the standardized residuals do not show any spatial autocorrelation.

(@) [3 pts] Report and interpret the REML-estimated fixed effects of date and whether or not a site is at TIA. Do the signs match what you'd expect? Why/why not?

```{r}
summary(reml_mod)
```
The fixed effects estimates from the REML-fitted models suggest that there was a very small effect of time, such that as time passed, log dioxane concentrations decreased. Additionally, there was an effect of whether the site is at the airport or not, such that sites on the airport tended to have a lower log dioxane concentration. The negative coefficient for the effect of time makes sense if there are no longer inputs of dioxane into the environment and it is naturally being transported/decomposed, or if there are active dioxane cleanup efforts. I was surprised that sites at the airport were likely to have lower dioxane concentrations since it is an industrial chemical. However, perhaps the non-airport sites were also industrial and/or are downstream of the airport.

(@) [2 pts] Use the REML-fitted model to create a 95% confidence interval for the expected log-concentration of dioxane in groundwater beneath the intersection of Drexel Rd. and 6th Ave. (32.1485, -110.9680) on May 28, 2007.

```{r}
drexel <- data.frame(AnalysisStartDate = "2007-05-28", airport = F, 
                     LatitudeMeasure = 32.1485, LongitudeMeasure = -110.9680)
drexel_sf <- st_as_sf(drexel, crs = "epsg:32612", 
                      coords = c("LatitudeMeasure", "LongitudeMeasure"))

pred_diox <- predict(reml_mod, newdata = drexel_sf, 
                     interval = "confidence", se.fit = T) ; pred_diox
```
(@) [4 pts] Use a basis function approach to model the log-concentration of dioxane while accounting for the possible effects of date and whether or not a site is located at TIA. Use your fitted model to create another 95% confidence interval for the log-concentration of dioxane at Drexel Rd. and 6th Ave. on the same date. Which method produced the narrower confidence interval?

```{r}
library(mgcv)

gam_mod <- gam(log_diox ~ as.POSIXct(AnalysisStartDate) + airport 
               + s(LongitudeMeasure, LatitudeMeasure), data = diox)
summary(gam_mod)
# plot(gam_mod)

pred_gam <- predict.gam(gam_mod, newdata = drexel, interval = "confidence", 
                        se.fit = T) ; pred_gam
```
The GAM method produced a narrower confidence interval due to estimating a smaller standard error.

## III. Canada Lynx [6 pts]

(@) [3 pts] Obtain the centered and scaled locations of two Canada lynx from the supplementary materials of [**Buderman et al. (2016)**](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12465). Use the functionality of the `mgcv` package to fit independent GAM models to each coordinate of the bivariate location measurements of individual BC03F03. **Use cubic regression splines**, and experiment with the dimension of the basis (i.e., number of basis functions) to find a fit that looks good to you. **PEC**.

```{r}
lynx <- read.csv("lynxdata.csv")
lynx <- subset(lynx, lynx$Individual == "BC03F03")
lynx$Date <- as.numeric(as.POSIXct(lynx$Date, format = "%m/%d/%Y"))

library(mgcv)
gam_lat <- gam(Latitude ~ s(Date, bs = "cr", k = 20), data = lynx)
# plot(gam_lat)
# gam.check(gam_lat)

gam_lon <- gam(Longitude ~ s(Date, bs = "cr", k = 30), data = lynx)
# gam.check(gam_lon)
```

(@) [3 pts] Make two plots in the spirit of Figure 1(b) from Buderman et al. (2016) using your fitted models. Where in the two plots do you see the biggest discrepancies between your fit and the one from Buderman et al. (2016)?

```{r}
ggplot(lynx, aes(x = as.POSIXct(Date), y = Longitude))+
  geom_point(aes(color = Data.Type))+
  geom_line(aes(y = predict(gam_lon)))+
  theme_light()+
  labs(color = "Accuracy/data class")

ggplot(lynx, aes(x = as.POSIXct(Date), y = Latitude))+
  geom_point(aes(color = Data.Type))+
  geom_line(aes(y = predict(gam_lat)))+
  theme_light()+
  labs(color = "Accuracy/data class")
```
I feel like my plots look less smooth than those in Buderman et al., but the overall patterns (where and how the line curves) are relatively conserved. For the GAM of latitude, there are some differences in the curvature after 2004, particularly when the location is at its most northern and it turns back south.
